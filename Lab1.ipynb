{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"06660d9a8c394c60ad300b93e268b6cb","deepnote_cell_type":"markdown"},"source":"# Lab 1 - Math 178, Spring 2024\n\nThis lab is due Thursday night of Week 2. You are encouraged to work in groups of up to 3 total students, but each student should submit their own file. (It's fine for everyone in the group to submit the same link.)\n\nThe goal of this lab is to produce a plot like what is shown in Figures 2.9, 2.10, 2.11, and 2.17 in the *Introduction to Statistical Learning with Applications in Python* textbook.\n\nPut the full names of everyone in your group (even if you're working alone) here. This makes grading easier.\n\n**Names**:","block_group":"e7ded295d37f4b9680acdf181ae94c90"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"13d6bfec1a6f4c7884550219fc44aaa1","deepnote_cell_type":"markdown"},"source":"## Generate the data\n\nOur true underlying function will be $f(x) = 3x^2$.\n\nCreate a 2000-by-2 pandas DataFrame with two columns, `\"x\"` and `\"y\"`.  The x-column should contain 2000 random values distributed uniformly between -5 and 5.  The y-column should should be defined using $y = f(x) + \\epsilon$, where $\\epsilon$ represents Gaussian random noise with mean `0`.  You can experiment with different standard deviations for this random noise (to set the standard deviation, use the `scale` keyword argument in NumPy).","block_group":"4a697751dd6b483aa06cab33bd1d2577"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"ba271321b3364a5f83036daf320827c9","deepnote_cell_type":"markdown"},"source":"## Plot the data\n\nDraw a scatter-plot of this data.  Chris recommends using Altair (and can best help if you use Altair), but you are welcome to use whatever you like, including Plotly, Seaborn, or Matplotlib.","block_group":"699c60fd1d5e469d8a9e20e342dfbdd5"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"c599be84f2c146bfb6a996b687fe90a4","deepnote_cell_type":"markdown"},"source":"## A function to compute train error and test error\n\nWrite a function `get_error` that takes three inputs, `train_size`, `k`, and `set_used`.  Descriptions of these arguments:\n* `train_size` represents the size of the training set to use as an integer.  (The `train_test_split` function also allows a decimal between `0` and `1`, but we want to specify the absolute number of rows to use.)\n* `k` represents the number of neighbors to use.\n* `set_used` will be the string `\"train\"` or `\"test\"`, and indicates whether we are computing the training error or the test error.\n\nWithin the function:\n* Divide the data into a training set and a test set using `train_test_split`.  Be sure to choose the number of training rows using the `train_size` argument.\n* Instantiate a KNN object from scikit-learn.  (Is this a regression problem or a classification problem?)\n* Fit the object to the training data.  (Fitting to all the data or to the test data is a major mistake.)\n* Compute the train mean-squared error or the test mean-squared error, according to the `set_used` argument.\n* Return this MSE.","block_group":"15f71ec70638464db0fc3255fa001302"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"d3866ec871f745da9efc751f65b2ee57","deepnote_cell_type":"markdown"},"source":"## Plot the results\n\n* Experiment with different values of `train_size` and `k` with the goal of making a plot similar to what is in Figure 2.17 in the textbook.  If you use Altair, you can have a log scale along the x-axis as shown here: https://altair-viz.github.io/gallery/line_with_log_scale.html (Warning: Deepnote does not have the latest version of Altair pre-installed, so you will probably need to use the attribute syntax, not the method syntax.)  For showing both curves together in Altair, I followed the IMDB example [here](https://altair-viz.github.io/user_guide/compound_charts.html#repeated-charts), but it might be simpler to just make the train curve and the test curve separately, and then layer them using `+`.\n* Using a log scale is not a requirement, but in my case it made the charts look better.  \n* Be sure to use k-inverse rather than k for the x-axis, so that more flexible values (where overfitting is more likely) occur to the right of the chart.  That is the general convention for these charts.\n* If your chart doesn't look at least approximately like what is shown in Figure 2.17, try changing parameters (including the standard deviation of the error from the very beginning of this lab) or check for mistakes.","block_group":"f7713c56c6b44a73be13c20635444d47"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"484a40583bee4246af730b5bc14a8d4e","deepnote_cell_type":"markdown"},"source":"## Submission\n\n* Using the `Share` button at the top right, enable public sharing, and enable Comment privileges. Then submit the created link on Canvas.","block_group":"225ed2094b1140db8c583d46277a0673"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"5df740e7bd6b4aaf94f83f4922dd9b7a","deepnote_cell_type":"markdown"},"source":"## Possible extensions\n\nThese are not required but some ideas for extra practice.\n\n* Our chart is like the right-hand panel of Figures 2.9 to 2.11.  Can you also make the left-hand panel?\n* Conceptually harder but also using the basic functionality of the `get_error` function: Can you make something like one of the charts shown in Figure 2.12?  I don't think this will be possible using the information in ISLP, so you will need to look up the definition of bias and variance somewhere else.  (They involve averaging over many choices of equal-sized training sets.  It will not be practical to use every possible choice of training set, because there are too many.)  I haven't tried this myself so I'm not sure how similar the outcome will be to what's shown in Figure 2.12.","block_group":"4ae8adef88ee41619368b7eb3540b6d0"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6f2e2a41-9217-483d-b456-640ec5ceb627' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2024-04-02T15:31:03.115Z"},"deepnote_notebook_id":"d81a382f352c461f8678889e74e48c5d","deepnote_execution_queue":[]}}