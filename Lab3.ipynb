{"cells":[{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"489881c848d24666a012452e3eee5fcb","deepnote_cell_type":"markdown"},"source":"# Lab 3 - Math 178, Spring 2024\n\nYou are encouraged to work in groups of up to 3 total students, but each student should submit their own file. (It's fine for everyone in the group to submit the same link.)\n\nPut the full names of everyone in your group (even if you're working alone) here. This makes grading easier.\n\n**Names**:","block_group":"9718829a07d443f39089de3636525725"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"933c018c725c41788c2ff2c0a582e450","deepnote_cell_type":"markdown"},"source":"The attached dataset `world_cup22.csv` is based on [this Kaggle dataset](https://www.kaggle.com/datasets/die9origephit/fifa-world-cup-2022-complete-dataset).  To make it more well-suited to prediction, the values in most of the columns (everything from \"possession\" and beyond) corresponds to *the team's previous match*.\n\n* Goal: Can we use statistics from a team's previous match to predict how many goals they will score in the World Cup?\n\nComment: You should not expect excellent performance, because it is of course very difficult to predict how many goals a team will score.  (And here we are not even considering the opponent, which is a hugely relevant piece of information.)","block_group":"c9b5f1a84464489f8f32d526b2dd0df8"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"c44361fb18794a748b7740986a3efd65","deepnote_cell_type":"markdown"},"source":"## Prepare the data","block_group":"0edc9a0a298f46f59b08daaaeefb711f"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"3a7712418c2444908ed8f640e673c2a0","deepnote_cell_type":"markdown"},"source":"* Read in the attached `world_cup22.csv` file and store it as a pandas DataFrame.","block_group":"0b2eea6d6f82451ebb33114ec55f71d8"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"e61f0cfb731749109caab0c170287dfd","deepnote_cell_type":"markdown"},"source":"* Rescale every column from \"month\" and beyond (i.e., every numeric column except for the \"number of goals\" column) to have mean (approximately) zero and standard deviation (approximately) one.\n\nThe most straightforward way to achieve this in my opinion is with the following code.  You should replace `???` here with code that rescales the pandas Series `col`.\n\n```\ndf.loc[:, \"month\":] = df.loc[:, \"month\":].apply(lambda col: ???, axis=0)\n```","block_group":"d714d8f48b7944ff9f18848602618d66"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"0bf5780a1f554dc8918fa22978bc273c","deepnote_cell_type":"markdown"},"source":"* Use `train_test_split` to divide the data into a training set of length `60` a test set of length `36`.  Use the `random_state` keyword argument so that you get consistent results.  Here `X_train` and `X_test` should be DataFrames with all of the rescaled numeric columns.  `y_train` and `y_test` should be pandas Series containing only the \"number of goals\" column.  (We will never use the \"team\" column in this lab; it's just there for your own interest, and it was crucial to preparing the data, because we needed the statistics from the team's previous match.)","block_group":"e9ddba80c5e2451fa6cd4979f51182ba"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"d8cfbdc97c544a5eb5b731282ea3abb0","deepnote_cell_type":"markdown"},"source":"## Overfitting with linear regression\n\nYour intuition should be that linear regression is not very prone to overfitting, because it is not a particularly flexible model (we simply choose one coefficient per predictor and an intercept).  However, when there are many features relative to the number of observations, then linear regression is indeed prone to overfitting.  We will see that this is the case here.","block_group":"7c94b9baa6794a27b3a65dc13fac36c8"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"58a37829c9f8456e96e6bda81365b7e4","deepnote_cell_type":"markdown"},"source":"* Fit a scikit-learn `LinearRegression` object to the training data.\n* What is the training Mean Squared Error?\n* What is the test Mean Squared Error?\n* Why does this suggest overfitting?","block_group":"7d4931dded0741a68a43acedf121e519"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"63676402197044479a91f73e9c8e73a8","deepnote_cell_type":"markdown"},"source":"## Aside: coefficient magnitudes\n\nExecute the following code to get a sense for which coefficients were deemed most important in our linear regression model.  (The following code assumes `reg` is the name of your fit `LinearRegression` object.  This code requires a recent version of Altair, which I've specified through the `requirements.txt` file and the Initialization notebook.  This should automatically be there for you if you duplicated this project.  If not, you can recreate it by clicking the Python Machine button at the lower left, and selecting `Initialization notebook`, and then copying what I have in the `requirements.txt` file.  Or if it's causing trouble, just ignore all this and delete the `.sort('x')` method in the below code.)\n\n```\nimport altair as alt\n\ndf_coef = pd.DataFrame({\n    'feature': reg.feature_names_in_,\n    'coef': reg.coef_\n})\n\nchart = alt.Chart(df_coef).mark_bar().encode(\n    x='coef',\n    y=alt.Y('feature').sort('x') # delete `sort('x')` if necessary\n).properties(\n    title='Coefficients'\n)\nchart\n```\n\nComment: In my preparation for this lab, these coefficient sizes have been very unstable.  That is another sign of overfitting.  So if you do this twice with different random states, do not expect similar results.\n\nComment 2: These coefficient sizes would not be meaningful (in relation to each other) if we had not rescaled the input columns to have equal standard deviations.","block_group":"d00431c4693647d4ae0fb5869cce2742"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"eae830bb1c2f42a793400e881e5184c7","deepnote_cell_type":"markdown"},"source":"## Preparation for cross validation","block_group":"05052c3384f64163b7614907847994e0"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"916d89f40dab438bbee95997a331fcfe","deepnote_cell_type":"markdown"},"source":"We saw above that using every column led to overfitting.  Here we will restrict ourselves to only using three columns as predictors.  But which three columns should we use?\n\n* Create a list of all possible length-3 tuples of column names from `X_train`.  (Be sure your triples contain strings, not pandas Series.  We want triples of column names, not triples of columns.)\n\nComment.  I did this using the `combinations` function from the `itertools` module, and converting the resulting generator into a list (just by wrapping it in the `list` function).\n\nComment 2.  You would not want to do this for all possible length-10 tuples, because there would be too many.  In this case, our list will have length 14,190, which is no concern.","block_group":"9ad01908eacb45fdbc0ba992ca94acae"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"bf17337168304598a162f188518a4651","deepnote_cell_type":"markdown"},"source":"* Choose 1,000 of these triples randomly using `rng.choice` where `rng` is a NumPy `default_rng` object; store the resulting NumPy array using the variable name `random_tuples`.  Use a `seed` keyword argument to `default_rng` so that you get reproducible results.  I recommend instantiating `rng` and calling `rng.choice` in the same cell, because this will help reproducibility.\n\nComment.  If you wanted to have for example length-10 tuples, then you should just do this step directly, without ever using `itertools`.","block_group":"09e063d0bcc244ccb700e50dbd53f8af"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"9bfc8f300a6e42d6bc87e24f070a3b39","deepnote_cell_type":"markdown"},"source":"## Cross validation\n\nOverview: For each triple of features in `random_tuples`, we will get an estimated Mean Squared Error using 10-fold cross-validation.  We will choose as columns those which produce the best (i.e., lowest) MSE.","block_group":"8966b998e4da49128c8b76d8ed7ae846"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"c8f7aa9693e14d88b90dd57b2e855671","deepnote_cell_type":"markdown"},"source":"Use scikit-learn's `cross_validate` function to generate a list as follows.\n* Each entry in the list will be a length-2 tuple consisting of 1st the columns and 2nd the MSE cross-validation score.\n* Specify to use 10-fold cross-validation using the `cv` keyword argument.\n* Specify `\"neg_mean_squared_error\"` as the `scoring` keyword argument to `cross_validate`.\n* Do not use the full `X_train` in `cross_validate`.  Instead only use the three columns in `triple`.\n* Compute the mean of the resulting `\"test_score\"`.  This will be the negative of the mean of the MSEs, so negate it to get a traditional (positive) MSE.\n\n```\nmse_list = []\n\nfor triple in random_tuples:\n    cv_results = cross_validate(???)\n    cv_mse = ???\n    mse_list.append((tuple(triple), cv_mse))\n```\n\nComment.  This code took about two minutes to run when I tried it.  If necessary you can decrease the number of triples used.\n\nComment 2.  The `tuple(triple)` is there to convert `triple` from a NumPy array into a `tuple`, so that it is hashable and is thus allowed to serve as a key to a dictionary.\n\nComment 3.  Reality check: when I ran the code, these were the first two elements of `mse_list`.  The triples represent the columns used and the numbers represent the corresponding cross-validation Mean Squared Errors.\n```\n[(('central channel', 'inbetween offers to receive', 'red cards'),\n  1.228113034518691),\n (('completed defensive line breaks', 'passes', 'crosses'),\n  1.3288270772012454)]\n```\n\n","block_group":"27ac7cfc49f3453bb2e0c4d0884463ed"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"07acb9a0b80e4009996f833e8bdcadab","deepnote_cell_type":"markdown"},"source":"* Convert `mse_list` to a dictionary and then to a pandas Series.  (It did not work when I tried to immediately convert it to a dictionary.)  Name the result `mse_series`.","block_group":"5056ac35da694fb78e55ae3867316fc8"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"20ed4e610ef34124b3e07bcdffdbf15a","deepnote_cell_type":"markdown"},"source":"* What triple of columns (from the thousand we tested) produces the lowest cross-validation MSE?  This is surprisingly easy to answer: use the `idxmin` method of a pandas Series.  What is the MSE in that case?","block_group":"a625be37763c413caed11018cce9eed8"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"6492217de27e41879c5a99a216203919","deepnote_cell_type":"markdown"},"source":"* Fit a `LinearRegression` object to the training data using only those three columns, and compute the training MSE and the test MSE.\n\nComment.  One time when I tried this, there was still considerable overfitting, but not as much as above.  Even with cross-validation, it is possible to overfit, especially when performing cross validation so many times.  Another time I tried this, there was no overfitting.  You should view the test MSE as the most reliable indicator of performance.","block_group":"79c65fe04b934faa82ee1b79212e4414"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"aa0d6d8399bb48da974ce8bdca22a70c","deepnote_cell_type":"markdown"},"source":"## Submission\n\n* Using the `Share` button at the top right, enable public sharing, and enable Comment privileges. Then submit the created link on Canvas.","block_group":"a53bf0ffd330478bac2f7a67b4a4ed28"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"46795ce129e34bebadd80feae0242e12","deepnote_cell_type":"markdown"},"source":"## Possible extensions\n\n* My original plan for this dataset was to illustrate bootstrap as in Section 5 of [this paper](https://www.stat.berkeley.edu/~breiman/bagging.pdf).  I changed the plan because I decided cross-validation was a more fundamental concept.\n* No attempt was made here to find the \"best\" linear regression model.  You could try using cross-validation to determine what is the ideal number of (and collection of) predictors.  Be sure to evaluate the ultimate performance on an unseen test set.\n* You could try doing basically the exact same thing except using KNN regression instead of linear regression.  (Here you will benefit from our having rescaled the predictor columns.)  Try using cross-validation to select the ideal columns and the ideal value of K (the number of neighbors considered).  I haven't tried this so there is some chance something goes wrong, due to being in such a high-dimensional space (i.e., with so many columns), but I think it will be fine.","block_group":"106af21bf84f42e199aeafcba447ea08"},{"cell_type":"markdown","metadata":{"cell_id":"4dfc615623f74083bb9dafa5978bc0af","deepnote_cell_type":"markdown"},"source":"","block_group":"84cda72cee5149f190e1df8468f99f3c"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=9741ebd5-9fb2-4e2d-9552-1f6a6411e06c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2024-04-28T19:30:09.931Z"},"deepnote_notebook_id":"dbdd5b7d422048b2b1291c7d9457f607","deepnote_execution_queue":[]}}