{
 "cells": [
  {
   "block_group": "495e47eac86840b1befb6a6b76a1d1e9",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5fcbe2d647524373a4da88481280c86e",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Lab 5 - Math 178, Spring 2024\n",
    "\n",
    "You are encouraged to work in groups of up to 3 total students, but each student should make a submission on Canvas. (It's fine for everyone in the group to submit the same link.)\n",
    "\n",
    "Put the full names of everyone in your group (even if you're working alone) here. This makes grading easier.\n",
    "\n",
    "**Names**:"
   ]
  },
  {
   "block_group": "3b5f8b3671cb42b397741b7ba9c2c945",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ecd2b4ec60cb4cc2857265500ae681b9",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Part 0 - Updating a pre-installed Python package on Deepnote\n",
    "\n",
    "For your final project (remember that the proposal is due the same day as this lab), some code might not work due to Deepnote not having the most recent libraries installed.  Here is an example of updating Altair from version 4.2.2 to version 5.3 in Deepnote.\n",
    "* On the left side, create a new file called `requirements.txt`.  (Be sure you spell this file name exactly as I did.)\n",
    "* Within this requirements.txt file, include the single line `altair==5.3` (no quotation marks or anything).\n",
    "* Click the Python version at the lower left (in the `Machine` section) and then click the `initialization notebook` option.  This should create an initialization notebook in the Notebooks section.  You don't need to change that notebook, but it needs to exist in order for Deepnote to know to use the `requirements.txt` file.\n",
    "* If everything went correctly, the left side of Deepnote should look like this.  (The two things to notice are the `Init` notebook and the `requirements.txt` file.)\n",
    "![Deepnote setup](sample_image.png)\n",
    "* Check that things are working by evaluating\n",
    "```\n",
    "import altair as alt\n",
    "alt.__version__\n",
    "```\n",
    "and ensuring it says some version starting with `5.3`.  You will probably need to click `Stop machine` at the lower left and then restart it."
   ]
  },
  {
   "block_group": "4c804a374733402497686d04879029a2",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1cc4af778d2742cd96f3be293cf762ad",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Part 1 - PCA with simulated data"
   ]
  },
  {
   "block_group": "76a55d7d040d4f2d90d529a961a5989c",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6dad134ee6e847a4b0046965c6f47e5f",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Define a NumPy random number generator object `rng` by using the `default_rng` function.  Specify a `seed` value so that you get reproducible results.\n",
    "* Using the `multivariate_normal` method of `rng`, define `200` data points drawn from a two-dimensional Gaussian distribution.  Keep the `mean` at the origin, but specify a covariance matrix `cov` so that the data is elongated in one direction, and so that it is *not* axis-aligned.  (PCA will not be interesting if our data is axis-aligned.  We want to have some significant correlation between the features.  There are only two features in our current case.)\n",
    "* If `arr` is a 200x2 NumPy array of data, we can display it in Altair using the following code.  (**Warning**.  This code will not work if you did not update to Altair 5.3 above.  I assume NumPy, pandas, and Altair have already been imported with the standard abbreviations.  We're specifying an explicit domain for the variables so that it's easier to tell what the slope is.  Feel free to change the domain, but I think it's easiest to use the same domain for both coordinates.)\n",
    "```\n",
    "df = pd.DataFrame(arr, columns=[\"x1\", \"x2\"])\n",
    "alt.Chart(df).mark_circle().encode(\n",
    "    x=alt.X(\"x1\").scale(domain=[-10,10]),\n",
    "    y=alt.Y(\"x2\").scale(domain=[-10,10])\n",
    ")\n",
    "```\n",
    "* If your data looks too symmetric (like a disk) or too axis-aligned, try changing your chosen covariance matrix (or, less likely, your random seed)."
   ]
  },
  {
   "block_group": "c71ddbbf30364d1e963a94b4f37257fe",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "eedc77edc90d4fdcb112f93a9dcf84c1",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Fit a `PCA` object from `sklearn.decomposition` to the data in `arr`."
   ]
  },
  {
   "block_group": "045a2a1dc3e24ab8bc847177bdd72580",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f6aa17a810b54f459b48202b4bc4bfc8",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Check the `components_` attribute of this fit `PCA` object.  Do you see how the rows of this matrix correspond to the distribution of the data?  (Sample final exam question type: Which of the following could be the principal components corresponding to the following data?)"
   ]
  },
  {
   "block_group": "9d826cd61f0e4b14b945f47b6440c77b",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "61e9a07fe8ea40ac97e5c286f9d1e5ee",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Using the `transform` method of our PCA object, add two new columns to our DataFrame corresponding to the principal component scores of our `arr` data.  Name these new columns `\"PC1\"` and `\"PC2\"`."
   ]
  },
  {
   "block_group": "94e8db78c2084ed39cf2f15ff2dd010a",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "85e8739704624c9c8a404c67b0be40ba",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Evaluate `df.var(axis=0)`.  This should produce four variance values.  Notice how the sum of the values for our original columns equals the sum of the values for our new columns."
   ]
  },
  {
   "block_group": "a451ca7e762241f596d8b15599f13ddc",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "039dddaefe574f9d9ca6822015473e02",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Check the `explained_variance_ratio_` attribute of our fit PCA object.  How could you compute these same numbers using the variance values just computed?"
   ]
  },
  {
   "block_group": "f8fb628c95c64761978438e54983d9f4",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "52f695b6d946455e81d96482ae15b6c6",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Add a color encoding using `alt.Color` to our Altair chart, using the new column \"PC1\".  Specify a color scheme by using `color=alt.Color(\"PC1\").scale(scheme=???)`.  You can see the choice of color schemes [here](https://vega.github.io/vega/docs/schemes/).  Choose a diverging color scheme (we want to be able to clearly differentiate between positive and negative scores)."
   ]
  },
  {
   "block_group": "cda60f9648fe4ca8aa619df13a34f144",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b0f619aecc9408a89f926ec08b0505b",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Do the same thing again, but now using \"PC2\" instead of \"PC1\" for the color scheme encoding."
   ]
  },
  {
   "block_group": "1f8201364e72492aad23d6a680bd37ec",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "035c8f1ee17645df93cac840c65096f1",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Sample exam question (no need to turn anything in for this question).  Given the principal component vectors, can you recognize which points in our original dataset will have the largest scores for those principal components?"
   ]
  },
  {
   "block_group": "5ef1fc875d344a3f91cc42a3cf0651b5",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6c3cc73fa8ca4bb3be2a6f55d5e0c7aa",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Part 2 - PCA with the Olivetti faces dataset"
   ]
  },
  {
   "block_group": "d98d3e63c3c249129dd8bbd34406a234",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1cd6caf2462e4f7fbbfa2d99694ebc27",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Using scikit-learn's `fetch_olivetti_faces` function (remember to import this function first), download the Olivetti faces dataset (along with the identifier values) using the following syntax.\n",
    "```\n",
    "X,y = fetch_olivetti_faces(return_X_y=True)\n",
    "``` "
   ]
  },
  {
   "block_group": "110af82586a547918e17f0182b5f4c7d",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7b7fb3af480a418b919bd20f1441081a",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* If you import Pyplot as follows\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "then you can display one of these faces (say the `151`st face) as follows.\n",
    "```\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(X[151].reshape((64, 64)), cmap=\"binary_r\");\n",
    "```"
   ]
  },
  {
   "block_group": "a72f1ba52ca946e1898bc5ac4da315ef",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0863e3e21c754b8d977ea62350964082",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* This corresponds to the `15`-th person in the dataset, as can be seen by evaluating the following: `y[151]`"
   ]
  },
  {
   "block_group": "ee64fcfa7bf54fc4b060a9c505b9ad57",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "007b5ea3a5e64708a4675caddd3c6c43",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Sample exam question (no need to turn anything in for this question).  We considered this dataset in terms of unsupervised learning.  Why would this dataset also be well-suited to use in supervised learning?"
   ]
  },
  {
   "block_group": "4a37fcd481a241a3aa00970be98b32a9",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bb6b07d26d4142139cf1815b815454aa",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Fit a new `PCA` object `pca_faces` to this dataset."
   ]
  },
  {
   "block_group": "8a5eec87c70749d6a9a83cd3b329b704",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "750b7e5fd87a47a69f4b6c87a02a7a56",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Display the first (0-th in Python numbering) principal component vector as an image (reshaped to 64-by-64 dimensions), as what we did above."
   ]
  },
  {
   "block_group": "34e000de84874e74acea8e8f8a4e37bc",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4fb13843338c40229e16e0d0c2e3586c",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* How many total principal components should be used to explain 90% of the variance?  (It's okay to use some guessing and checking to find this value, but if you want a difficult Python exercise, try to automate this without using any explicit loop.  See the *Possible extensions* section below for the approach I would use.)"
   ]
  },
  {
   "block_group": "3a76c782ccd7408e80fad4bfa6de12fe",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a4bd95452b3b4303a4b263d3aa16a568",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Fit another PCA object `pca2` to this face data, but this time, when instantiating the PCA object, specify that `n` components should be used, where `n` is the number needed to explain 90% of the variance (as in the previous question).  Don't worry about off-by-one errors due to Python indexing starting at 0.  (Typo corrected Tuesday June 4th to change 80% to 90%.)"
   ]
  },
  {
   "block_group": "e3a6973dce234ab38395f779cc691a39",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2ae77a1f31bd45c6870f540d1314b5a9",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Transform the data and save it in a new variable, `X_transform`."
   ]
  },
  {
   "block_group": "9236187a29d8489880ae16128f975273",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f9826a5eef5a4a3b980daef49c6ab0ef",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Evaluate `X_transform[151]`.  How many numbers are there?  What do these numbers represent? "
   ]
  },
  {
   "block_group": "bf8772e3e470470cacba341924564af5",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "36593731531d45479de30577e0c4228a",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Convince yourself that the following corresponds to the 151-st face projected onto the n-dimensional subspace, spanned by the principal components we just found.  (The `dot` method is used for matrix multiplication.)\n",
    "```\n",
    "face_projection = np.matmul(X_transform[151], pca2.components_)\n",
    "```"
   ]
  },
  {
   "block_group": "0edcf184c9de43e2a5f05d4d6e827626",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc16f336dcf1421db3061385e8bdf102",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Display this projected 151st face.  It should look in some ways similar to the original face displayed above.  (It should look much closer to that face than our first principal component \"eigenface\" did.  If it looks identical to the 151st face, then something went wrong with restricting the number of components.)"
   ]
  },
  {
   "block_group": "0b3dda78223b41f1b6ea46458aeb4688",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7fd3e3bdd66e4e5c9f44a1d559d1e12b",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Submission\n",
    "\n",
    "* Using the `Share` button at the top right, enable public sharing, and enable Comment privileges. Then submit the created link on Canvas."
   ]
  },
  {
   "block_group": "007d2b22e3c149b2a5859614c37169db",
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3f8dff7e5c7140648251478a1fe1518a",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Possible extensions\n",
    "\n",
    "* One interesting extension would be to perform some sort of facial recognition on this dataset using in part PCA.  There are only 400 faces in the entire dataset, even less if you hold out a test set, so I doubt a neural network is the right thing to use (but I could be wrong).\n",
    "* I think it would be interesting to take only two or three people in this dataset (20 or 30 face images) and perform PCA on this portion of the dataset using only two principal components (two so we can plot it).  Then make a scatter plot of the transformed data (the scores), and color the points according to which face they corresponded.  Do the same faces appear on the same part of the scatter plot?\n",
    "* A Python exercise (not a data science exercise) would be to automate finding the index where 90% of variance gets explained.  I think what I would use is `np.cumsum` and `np.nonzero`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=55513ea8-bfe2-4d74-8697-f7639ffaa6c8' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "857fe228182349899f53b44bbff0783b",
  "deepnote_persisted_session": {
   "createdAt": "2024-05-27T01:03:39.223Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}